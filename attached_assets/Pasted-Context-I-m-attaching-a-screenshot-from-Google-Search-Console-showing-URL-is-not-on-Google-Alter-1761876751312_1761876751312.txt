Context:
I’m attaching a screenshot from Google Search Console showing “URL is not on Google — Alternative page with proper canonical” for https://www.cararth.com/. I am not technical — please fix the indexing issue end-to-end and explain plainly what you changed.
Please perform these checks and fixes (in this order), using the screenshot for context:
Check page headers & meta
Fetch the page headers and HTML <head> for https://www.cararth.com/.
Report any X-Robots-Tag headers or <meta name="robots" content="noindex">.
If found, remove noindex from pages we want indexed, or explain why it’s present.
Check canonical tags
Inspect <link rel="canonical"> on this page and any obvious alternate pages (www vs non-www, http vs https, trailing slash).
If canonical points to a different URL, update the canonical so it points to the preferred URL we want indexed (https://www.cararth.com/) — or, if the preferred canonical should be the other URL, set up a 301 redirect and update sitemap/internal links accordingly.
Explain what you changed in plain language.
Verify robots.txt
Open https://www.cararth.com/robots.txt and ensure it does NOT block the homepage or main paths.
If there’s a blocking rule, remove or fix it and add Sitemap: https://www.cararth.com/sitemap.xml.
Create / Update sitemap
Generate or update /public/sitemap.xml that includes the homepage and main demo routes (/, /sell, /throttle-talk, /demo-listings, /used-cars-in-hyderabad, /used-cars-in-delhi-ncr).
Use canonical URLs (https + www or chosen canonical).
Submit the sitemap to Google Search Console (use the API or provide instructions and a screenshot showing the sitemap submitted).
Check redirects & canonical consistency
Ensure a single canonical domain is enforced by 301 redirects (choose https://www.cararth.com/ or https://cararth.com/), and internal links use that form.
If redirects are missing or inconsistent, add simple redirect rules in the Replit server config or app (or in Next.js vercel.json/rewrites if applicable).
Server rendering / fetch test
Run a live fetch that shows what Googlebot would see: curl -L https://www.cararth.com/ and capture first 200 lines of HTML. If content is missing due to client-side rendering, create a simple pre-rendered HTML snapshot for the homepage so Google can index it.
Run Google Search Console TEST LIVE URL steps and include the results (screenshot).
Request indexing
After the fixes, use GSC to TEST LIVE URL and then REQUEST INDEXING for the canonical URL. Attach screenshots of the successful live test and the indexing request submission.
Deliverables (what I expect back)
Short plain-English summary of what you found and what you changed (3–5 bullets).
Files you modified (list). If changed code/config, commit to branch: fix/gsc-indexing and open a PR.
Console output or screenshots proving:
curl -I https://www.cararth.com/ headers (showing no X-Robots-Tag: noindex and correct 200/301 as appropriate)
Updated robots.txt content (if edited)
sitemap.xml file content and GSC sitemap submission screenshot
GSC URL Inspection TEST LIVE URL result screenshot showing “Page can be indexed” (or equivalent) and REQUEST INDEXING confirmation.
If you could not fix something (e.g., hosting restriction), explain clearly what needs to be done and by whom.
If you must choose priorities (do this first)
Fix/remove noindex meta/header → Fix canonical mismatch → Ensure sitemap & robots.txt are correct → Submit sitemap & request indexing.
Notes / Tone:
Keep explanations non-technical and use plain language (I’m not technical).
If you change anything live, confirm it with a screenshot and the commit/PR link.
If you need permission/access to GSC or server settings, tell me exactly what access is required and how to provide it.
Start now. I’ve attached the GSC screenshot for reference. Thank you.